{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing and Understanding\n",
    "\n",
    "神经网络的黑箱特性是科研所不太喜欢的，对于高维复杂联系，很难做解释，不过可视化分析给了一种良好的方向，因此这里对可视化做一些基本介绍。主要参考了：['How neural networks learn' - Part I: Feature Visualization](https://www.youtube.com/watch?v=McgxRxi2Jqo&t=424s), [Lecture 12 | Visualizing and Understanding](https://www.youtube.com/watch?v=6wcs6szJWMY)等。\n",
    "\n",
    "## Feature Visualization\n",
    "\n",
    "首先，用一些方法看看训练后的网络有什么特点，即feature visualization。\n",
    "\n",
    "这里就是一篇比较经典的可视化的论文，[Visualizing and Understanding Convolutional Networks](https://arxiv.org/abs/1311.2901) ，它在训练一个分类的卷积神经网络的同时，还同时训练了一个反向的，deconvolution的网络来可视化feature到底学到了什么。deconvolution的意思就是取一个训练后的神经元，然后反向重现出图片的内容。这样对每层的神经元进行分析，就可以还原出对应的图片，可以发现第一层的神经元表达了一些简单的结构，点，线等等；第二层就能展示一些更复杂的结构，到最后一层就基本数还原出原图像了。\n",
    "\n",
    "不过这个技术必须要有特定的输入来训练网络，没有特定的输入，一些特征是分析不了的。这种时候有其他的一些方法，一个比较有名的例子是这样的。首先一个随机的图片，输入到一个神经网络，这里看其中某些神经元的变化，通过梯度可以指导什么输入更能激活这些神经元，这样通过循环计算就能得到激活这些神经元的图像是什么样的。这里是一种梯度上升的做法，可以参考：[梯度上升可视化卷积神经网络](https://zhuanlan.zhihu.com/p/30403766)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
